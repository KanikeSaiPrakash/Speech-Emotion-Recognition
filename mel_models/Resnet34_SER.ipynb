{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "invalid-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "import torch.optim as optim \n",
    "from torch_lr_finder import *\n",
    "from torch_lr_finder import LRFinder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import asarray\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('checkpoints/'):\n",
    "        os.makedirs('checkpoints/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = A.Compose([\n",
    "     \n",
    "                A.ShiftScaleRotate(shift_limit = 0.1,\n",
    "                                    scale_limit = 0.1,\n",
    "                                    rotate_limit = 30),\n",
    "                A.Normalize(mean=[0.1307], std=[0.3081])\n",
    "\n",
    "            ])\n",
    "\n",
    "      \n",
    "\n",
    "def valid_tfm(size):\n",
    "    return A.Compose([ A.Resize(size, size) ])\n",
    "\n",
    "tfms = transforms.Compose([\n",
    "    \n",
    "    transforms.RandomRotation(degrees=(-10, 10)),\n",
    "    transforms.RandomAffine(degrees=(-16, 16)),\n",
    "    #transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "    transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "                           \n",
    "                          ])\n",
    "v_tfms = transforms.Compose([\n",
    "    transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "path = []\n",
    "label_conversion = {'01': 'neutral',\n",
    "                            '02': 'happy',\n",
    "                            '03': 'sad',\n",
    "                            '04': 'angry',\n",
    "                            '05': 'fear',\n",
    "                            '06': 'disgust'}\n",
    "        \n",
    "    \n",
    "for subdirs, dir_, files in os.walk('specs_train'):\n",
    "    for filenames in files:\n",
    "        for emotion_number, emotions in label_conversion.items():\n",
    "            if(filenames[6:8] == emotion_number):\n",
    "                path.append(os.path.join(subdirs, filenames))\n",
    "                label.append(emotions)\n",
    "df = pd.DataFrame(label, columns = ['label'])\n",
    "df = pd.concat([df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "df.label.value_counts()\n",
    "df.to_csv('final_specs.csv', index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df  = pd.read_csv('final_specs.csv')\n",
    "final_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = final_df['path'].values, final_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-consideration",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataBunch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-79d32c140fba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m data = ImageDataBunch.from_folder(specs_train, train='.', valid_pct=0.2,\n\u001b[0m\u001b[0;32m      3\u001b[0m         ds_tfms=None, size=[224,224], num_workers=4).normalize(imagenet_stats)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataBunch' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "data = ImageDataBunch.from_folder(specs_train, train='.', valid_pct=0.2,\n",
    "        ds_tfms=None, size=[224,224], num_workers=4).normalize(imagenet_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
